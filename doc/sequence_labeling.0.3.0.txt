> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_CRF --embedding glove-840B --fold-count 10

training runtime: 29956.487 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 91.01
                  precision    recall  f1-score   support

             LOC     0.9153    0.9394    0.9272      1668
            MISC     0.8023    0.7977    0.8000       702
             ORG     0.8982    0.8820    0.8900      1661
             PER     0.9610    0.9598    0.9604      1617

all (micro avg.)     0.9095    0.9108    0.9101      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 91.38
                  precision    recall  f1-score   support

             LOC     0.9270    0.9371    0.9320      1668
            MISC     0.8127    0.8034    0.8080       702
             ORG     0.8931    0.8898    0.8914      1661
             PER     0.9606    0.9660    0.9633      1617

all (micro avg.)     0.9127    0.9148    0.9138      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 90.97
                  precision    recall  f1-score   support

             LOC     0.9204    0.9359    0.9281      1668
            MISC     0.8107    0.7806    0.7954       702
             ORG     0.8852    0.8910    0.8881      1661
             PER     0.9657    0.9579    0.9618      1617

all (micro avg.)     0.9097    0.9097    0.9097      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 90.97
                  precision    recall  f1-score   support

             LOC     0.9110    0.9329    0.9218      1668
            MISC     0.8290    0.7806    0.8041       702
             ORG     0.8828    0.8983    0.8905      1661
             PER     0.9628    0.9604    0.9616      1617

all (micro avg.)     0.9078    0.9117    0.9097      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 90.92
                  precision    recall  f1-score   support

             LOC     0.9149    0.9347    0.9247      1668
            MISC     0.8356    0.7892    0.8117       702
             ORG     0.8809    0.8904    0.8856      1661
             PER     0.9535    0.9629    0.9582      1617

all (micro avg.)     0.9067    0.9117    0.9092      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 91.25
                  precision    recall  f1-score   support

             LOC     0.9189    0.9371    0.9279      1668
            MISC     0.8076    0.8191    0.8133       702
             ORG     0.8934    0.8880    0.8907      1661
             PER     0.9600    0.9641    0.9620      1617

all (micro avg.)     0.9093    0.9157    0.9125      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 91.03
                  precision    recall  f1-score   support

             LOC     0.9162    0.9371    0.9265      1668
            MISC     0.8109    0.8063    0.8086       702
             ORG     0.8879    0.8826    0.8853      1661
             PER     0.9664    0.9604    0.9634      1617

all (micro avg.)     0.9092    0.9115    0.9103      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 91.07
                  precision    recall  f1-score   support

             LOC     0.9233    0.9376    0.9304      1668
            MISC     0.8126    0.8091    0.8108       702
             ORG     0.8826    0.8874    0.8850      1661
             PER     0.9604    0.9598    0.9601      1617

all (micro avg.)     0.9083    0.9132    0.9107      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 90.90
                  precision    recall  f1-score   support

             LOC     0.9108    0.9365    0.9234      1668
            MISC     0.8129    0.8048    0.8089       702
             ORG     0.8964    0.8808    0.8886      1661
             PER     0.9551    0.9604    0.9578      1617

all (micro avg.)     0.9074    0.9106    0.9090      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 90.78
                  precision    recall  f1-score   support

             LOC     0.9198    0.9347    0.9271      1668
            MISC     0.8200    0.7721    0.7953       702
             ORG     0.8729    0.8928    0.8827      1661
             PER     0.9616    0.9604    0.9610      1617

all (micro avg.)     0.9060    0.9095    0.9078      5648

----------------------------------------------------------------------

** Worst ** model scores - run 9
                  precision    recall  f1-score   support

             LOC     0.9198    0.9347    0.9271      1668
            MISC     0.8200    0.7721    0.7953       702
             ORG     0.8729    0.8928    0.8827      1661
             PER     0.9616    0.9604    0.9610      1617

all (micro avg.)     0.9060    0.9095    0.9078      5648


** Best ** model scores - run 1
                  precision    recall  f1-score   support

             LOC     0.9270    0.9371    0.9320      1668
            MISC     0.8127    0.8034    0.8080       702
             ORG     0.8931    0.8898    0.8914      1661
             PER     0.9606    0.9660    0.9633      1617

all (micro avg.)     0.9127    0.9148    0.9138      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9178    0.9363    0.9269      1668
            MISC     0.8154    0.7963    0.8056       702
             ORG     0.8873    0.8883    0.8878      1661
             PER     0.9607    0.9612    0.9610      1617

all (micro avg.)     0.9087    0.9119    0.9103


> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_CRF --embedding glove-840B --fold-count 10 --train-with-validation-set

training runtime: 75450.822 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 91.34
                  precision    recall  f1-score   support

             LOC     0.9154    0.9406    0.9279      1668
            MISC     0.8218    0.7949    0.8081       702
             ORG     0.8936    0.8946    0.8941      1661
             PER     0.9641    0.9623    0.9632      1617

all (micro avg.)     0.9116    0.9152    0.9134      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 91.23
                  precision    recall  f1-score   support

             LOC     0.9160    0.9418    0.9288      1668
            MISC     0.8151    0.7977    0.8063       702
             ORG     0.8977    0.8880    0.8929      1661
             PER     0.9599    0.9610    0.9604      1617

all (micro avg.)     0.9110    0.9136    0.9123      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 91.34
                  precision    recall  f1-score   support

             LOC     0.9154    0.9400    0.9275      1668
            MISC     0.8240    0.8134    0.8186       702
             ORG     0.8868    0.8916    0.8892      1661
             PER     0.9665    0.9623    0.9644      1617

all (micro avg.)     0.9103    0.9164    0.9134      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 91.45
                  precision    recall  f1-score   support

             LOC     0.9231    0.9424    0.9327      1668
            MISC     0.8008    0.8077    0.8043       702
             ORG     0.9056    0.8892    0.8973      1661
             PER     0.9571    0.9647    0.9609      1617

all (micro avg.)     0.9126    0.9164    0.9145      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 91.18
                  precision    recall  f1-score   support

             LOC     0.9175    0.9400    0.9286      1668
            MISC     0.7978    0.8148    0.8062       702
             ORG     0.9022    0.8832    0.8926      1661
             PER     0.9570    0.9629    0.9599      1617

all (micro avg.)     0.9093    0.9143    0.9118      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 91.69
                  precision    recall  f1-score   support

             LOC     0.9241    0.9412    0.9326      1668
            MISC     0.8282    0.8034    0.8156       702
             ORG     0.8989    0.8940    0.8965      1661
             PER     0.9642    0.9654    0.9648      1617

all (micro avg.)     0.9167    0.9171    0.9169      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 91.35
                  precision    recall  f1-score   support

             LOC     0.9273    0.9400    0.9336      1668
            MISC     0.8040    0.8063    0.8051       702
             ORG     0.8892    0.8940    0.8916      1661
             PER     0.9634    0.9610    0.9622      1617

all (micro avg.)     0.9111    0.9159    0.9135      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 91.56
                  precision    recall  f1-score   support

             LOC     0.9304    0.9371    0.9337      1668
            MISC     0.8328    0.7877    0.8097       702
             ORG     0.8891    0.9073    0.8981      1661
             PER     0.9502    0.9685    0.9593      1617

all (micro avg.)     0.9124    0.9187    0.9156      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 91.29
                  precision    recall  f1-score   support

             LOC     0.9220    0.9353    0.9286      1668
            MISC     0.8262    0.7920    0.8087       702
             ORG     0.8854    0.9025    0.8939      1661
             PER     0.9627    0.9586    0.9606      1617

all (micro avg.)     0.9113    0.9145    0.9129      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 91.27
                  precision    recall  f1-score   support

             LOC     0.9144    0.9412    0.9276      1668
            MISC     0.8048    0.8048    0.8048       702
             ORG     0.8985    0.8904    0.8945      1661
             PER     0.9646    0.9604    0.9625      1617

all (micro avg.)     0.9105    0.9148    0.9127      5648

----------------------------------------------------------------------

** Worst ** model scores - run 4
                  precision    recall  f1-score   support

             LOC     0.9175    0.9400    0.9286      1668
            MISC     0.7978    0.8148    0.8062       702
             ORG     0.9022    0.8832    0.8926      1661
             PER     0.9570    0.9629    0.9599      1617

all (micro avg.)     0.9093    0.9143    0.9118      5648


** Best ** model scores - run 5
                  precision    recall  f1-score   support

             LOC     0.9241    0.9412    0.9326      1668
            MISC     0.8282    0.8034    0.8156       702
             ORG     0.8989    0.8940    0.8965      1661
             PER     0.9642    0.9654    0.9648      1617

all (micro avg.)     0.9167    0.9171    0.9169      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9205    0.9400    0.9302      1668
            MISC     0.8156    0.8023    0.8088       702
             ORG     0.8947    0.8935    0.8941      1661
             PER     0.9610    0.9627    0.9618      1617

all (micro avg.)     0.9117    0.9157    0.9137



> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidGRU_CRF --embedding glove-840B --fold-count 10

training runtime: 42159.586 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 90.37
                  precision    recall  f1-score   support

             LOC     0.9370    0.9269    0.9319      1668
            MISC     0.7903    0.7621    0.7759       702
             ORG     0.8590    0.8983    0.8782      1661
             PER     0.9471    0.9641    0.9556      1617

all (micro avg.)     0.8988    0.9086    0.9037      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 90.55
                  precision    recall  f1-score   support

             LOC     0.9275    0.9353    0.9313      1668
            MISC     0.7724    0.7977    0.7849       702
             ORG     0.8850    0.8850    0.8850      1661
             PER     0.9409    0.9641    0.9524      1617

all (micro avg.)     0.8994    0.9117    0.9055      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 89.91
                  precision    recall  f1-score   support

             LOC     0.9127    0.9341    0.9233      1668
            MISC     0.7988    0.7635    0.7808       702
             ORG     0.8616    0.8772    0.8693      1661
             PER     0.9476    0.9617    0.9546      1617

all (micro avg.)     0.8942    0.9040    0.8991      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 90.32
                  precision    recall  f1-score   support

             LOC     0.9211    0.9305    0.9257      1668
            MISC     0.7806    0.7806    0.7806       702
             ORG     0.8782    0.8772    0.8777      1661
             PER     0.9547    0.9635    0.9591      1617

all (micro avg.)     0.9008    0.9056    0.9032      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 89.91
                  precision    recall  f1-score   support

             LOC     0.8926    0.9365    0.9140      1668
            MISC     0.8063    0.7707    0.7881       702
             ORG     0.8991    0.8633    0.8808      1661
             PER     0.9367    0.9604    0.9484      1617

all (micro avg.)     0.8971    0.9012    0.8991      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 90.22
                  precision    recall  f1-score   support

             LOC     0.9282    0.9305    0.9293      1668
            MISC     0.7531    0.7821    0.7673       702
             ORG     0.8888    0.8802    0.8845      1661
             PER     0.9333    0.9697    0.9512      1617

all (micro avg.)     0.8961    0.9085    0.9022      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 90.49
                  precision    recall  f1-score   support

             LOC     0.9135    0.9365    0.9248      1668
            MISC     0.7816    0.7849    0.7832       702
             ORG     0.8955    0.8772    0.8863      1661
             PER     0.9477    0.9635    0.9555      1617

all (micro avg.)     0.9019    0.9079    0.9049      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 89.90
                  precision    recall  f1-score   support

             LOC     0.9070    0.9353    0.9209      1668
            MISC     0.7523    0.8048    0.7777       702
             ORG     0.8846    0.8766    0.8806      1661
             PER     0.9357    0.9623    0.9488      1617

all (micro avg.)     0.8888    0.9095    0.8990      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 90.09
                  precision    recall  f1-score   support

             LOC     0.9105    0.9329    0.9215      1668
            MISC     0.7874    0.7650    0.7760       702
             ORG     0.8844    0.8844    0.8844      1661
             PER     0.9341    0.9641    0.9489      1617

all (micro avg.)     0.8951    0.9067    0.9009      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 89.96
                  precision    recall  f1-score   support

             LOC     0.9045    0.9365    0.9202      1668
            MISC     0.8259    0.7635    0.7935       702
             ORG     0.8725    0.8772    0.8748      1661
             PER     0.9360    0.9586    0.9471      1617

all (micro avg.)     0.8953    0.9039    0.8996      5648

----------------------------------------------------------------------

** Worst ** model scores - run 7
                  precision    recall  f1-score   support

             LOC     0.9070    0.9353    0.9209      1668
            MISC     0.7523    0.8048    0.7777       702
             ORG     0.8846    0.8766    0.8806      1661
             PER     0.9357    0.9623    0.9488      1617

all (micro avg.)     0.8888    0.9095    0.8990      5648


** Best ** model scores - run 1
                  precision    recall  f1-score   support

             LOC     0.9275    0.9353    0.9313      1668
            MISC     0.7724    0.7977    0.7849       702
             ORG     0.8850    0.8850    0.8850      1661
             PER     0.9409    0.9641    0.9524      1617

all (micro avg.)     0.8994    0.9117    0.9055      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9154    0.9335    0.9243      1668
            MISC     0.7849    0.7775    0.7808       702
             ORG     0.8809    0.8797    0.8802      1661
             PER     0.9414    0.9632    0.9521      1617

all (micro avg.)     0.8967    0.9068    0.9017 


> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidGRU_CRF --embedding glove-840B --fold-count 10 --train-with-validation-set

training runtime: 112655.109 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 91.13
                  precision    recall  f1-score   support

             LOC     0.9258    0.9353    0.9305      1668
            MISC     0.8157    0.8006    0.8081       702
             ORG     0.8883    0.8904    0.8894      1661
             PER     0.9425    0.9734    0.9577      1617

all (micro avg.)     0.9065    0.9163    0.9113      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 91.40
                  precision    recall  f1-score   support

             LOC     0.9246    0.9406    0.9325      1668
            MISC     0.8157    0.8006    0.8081       702
             ORG     0.8909    0.8898    0.8904      1661
             PER     0.9579    0.9709    0.9644      1617

all (micro avg.)     0.9112    0.9170    0.9140      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 90.90
                  precision    recall  f1-score   support

             LOC     0.9305    0.9311    0.9308      1668
            MISC     0.8091    0.8091    0.8091       702
             ORG     0.8669    0.8983    0.8823      1661
             PER     0.9562    0.9592    0.9577      1617

all (micro avg.)     0.9037    0.9143    0.9090      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 91.21
                  precision    recall  f1-score   support

             LOC     0.9242    0.9359    0.9300      1668
            MISC     0.7943    0.7977    0.7960       702
             ORG     0.8935    0.8989    0.8962      1661
             PER     0.9531    0.9672    0.9601      1617

all (micro avg.)     0.9075    0.9168    0.9121      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 90.66
                  precision    recall  f1-score   support

             LOC     0.9178    0.9311    0.9244      1668
            MISC     0.8092    0.7792    0.7939       702
             ORG     0.8809    0.8862    0.8836      1661
             PER     0.9508    0.9678    0.9592      1617

all (micro avg.)     0.9036    0.9095    0.9066      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 91.04
                  precision    recall  f1-score   support

             LOC     0.9282    0.9305    0.9293      1668
            MISC     0.8128    0.7977    0.8052       702
             ORG     0.8834    0.8898    0.8866      1661
             PER     0.9537    0.9672    0.9604      1617

all (micro avg.)     0.9084    0.9125    0.9104      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 90.61
                  precision    recall  f1-score   support

             LOC     0.9219    0.9347    0.9283      1668
            MISC     0.7886    0.7863    0.7874       702
             ORG     0.8757    0.8862    0.8809      1661
             PER     0.9553    0.9654    0.9603      1617

all (micro avg.)     0.9015    0.9108    0.9061      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 91.21
                  precision    recall  f1-score   support

             LOC     0.9265    0.9365    0.9314      1668
            MISC     0.8057    0.8091    0.8074       702
             ORG     0.8906    0.8922    0.8914      1661
             PER     0.9513    0.9660    0.9586      1617

all (micro avg.)     0.9082    0.9161    0.9121      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 91.13
                  precision    recall  f1-score   support

             LOC     0.9235    0.9335    0.9284      1668
            MISC     0.8169    0.8006    0.8086       702
             ORG     0.8821    0.8964    0.8892      1661
             PER     0.9604    0.9604    0.9604      1617

all (micro avg.)     0.9088    0.9138    0.9113      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 91.11
                  precision    recall  f1-score   support

             LOC     0.9311    0.9323    0.9317      1668
            MISC     0.8052    0.7949    0.8000       702
             ORG     0.8720    0.9067    0.8890      1661
             PER     0.9622    0.9598    0.9610      1617

all (micro avg.)     0.9067    0.9155    0.9111      5648

----------------------------------------------------------------------

** Worst ** model scores - run 6
                  precision    recall  f1-score   support

             LOC     0.9219    0.9347    0.9283      1668
            MISC     0.7886    0.7863    0.7874       702
             ORG     0.8757    0.8862    0.8809      1661
             PER     0.9553    0.9654    0.9603      1617

all (micro avg.)     0.9015    0.9108    0.9061      5648


** Best ** model scores - run 1
                  precision    recall  f1-score   support

             LOC     0.9246    0.9406    0.9325      1668
            MISC     0.8157    0.8006    0.8081       702
             ORG     0.8909    0.8898    0.8904      1661
             PER     0.9579    0.9709    0.9644      1617

all (micro avg.)     0.9112    0.9170    0.9140      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9254    0.9341    0.9297      1668
            MISC     0.8073    0.7976    0.8024       702
             ORG     0.8824    0.8935    0.8879      1661
             PER     0.9543    0.9657    0.9600      1617

all (micro avg.)     0.9066    0.9143    0.9104 


> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_CNN --embedding glove-840B --fold-count 10

training runtime: 28500.657 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 89.64
                  precision    recall  f1-score   support

             LOC     0.9118    0.9239    0.9178      1668
            MISC     0.7991    0.7877    0.7934       702
             ORG     0.8385    0.8910    0.8640      1661
             PER     0.9502    0.9555    0.9528      1617

all (micro avg.)     0.8867    0.9063    0.8964      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 89.96
                  precision    recall  f1-score   support

             LOC     0.9135    0.9311    0.9222      1668
            MISC     0.8028    0.8120    0.8074       702
             ORG     0.8401    0.8856    0.8623      1661
             PER     0.9538    0.9573    0.9556      1617

all (micro avg.)     0.8890    0.9104    0.8996      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 89.48
                  precision    recall  f1-score   support

             LOC     0.9091    0.9293    0.9191      1668
            MISC     0.7884    0.7963    0.7923       702
             ORG     0.8281    0.8814    0.8539      1661
             PER     0.9574    0.9579    0.9577      1617

all (micro avg.)     0.8831    0.9069    0.8948      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 89.56
                  precision    recall  f1-score   support

             LOC     0.9059    0.9347    0.9200      1668
            MISC     0.8000    0.7863    0.7931       702
             ORG     0.8472    0.8712    0.8590      1661
             PER     0.9473    0.9567    0.9520      1617

all (micro avg.)     0.8875    0.9039    0.8956      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 89.12
                  precision    recall  f1-score   support

             LOC     0.8959    0.9341    0.9146      1668
            MISC     0.7732    0.7963    0.7846       702
             ORG     0.8462    0.8675    0.8567      1661
             PER     0.9421    0.9561    0.9490      1617

all (micro avg.)     0.8791    0.9037    0.8912      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 89.19
                  precision    recall  f1-score   support

             LOC     0.9060    0.9299    0.9178      1668
            MISC     0.7717    0.7849    0.7782       702
             ORG     0.8342    0.8814    0.8571      1661
             PER     0.9534    0.9493    0.9513      1617

all (micro avg.)     0.8808    0.9032    0.8919      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 89.19
                  precision    recall  f1-score   support

             LOC     0.9017    0.9347    0.9179      1668
            MISC     0.7880    0.8048    0.7963       702
             ORG     0.8373    0.8675    0.8522      1661
             PER     0.9430    0.9524    0.9477      1617

all (micro avg.)     0.8802    0.9039    0.8919      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 89.48
                  precision    recall  f1-score   support

             LOC     0.9124    0.9305    0.9213      1668
            MISC     0.8011    0.7977    0.7994       702
             ORG     0.8281    0.8874    0.8567      1661
             PER     0.9432    0.9542    0.9487      1617

all (micro avg.)     0.8819    0.9081    0.8948      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 89.61
                  precision    recall  f1-score   support

             LOC     0.9001    0.9347    0.9171      1668
            MISC     0.7954    0.7920    0.7937       702
             ORG     0.8474    0.8796    0.8632      1661
             PER     0.9485    0.9567    0.9526      1617

all (micro avg.)     0.8854    0.9070    0.8961      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 89.68
                  precision    recall  f1-score   support

             LOC     0.9071    0.9311    0.9189      1668
            MISC     0.7872    0.8063    0.7966       702
             ORG     0.8453    0.8814    0.8630      1661
             PER     0.9452    0.9604    0.9528      1617

all (micro avg.)     0.8846    0.9093    0.8968      5648

----------------------------------------------------------------------

** Worst ** model scores - run 4
                  precision    recall  f1-score   support

             LOC     0.8959    0.9341    0.9146      1668
            MISC     0.7732    0.7963    0.7846       702
             ORG     0.8462    0.8675    0.8567      1661
             PER     0.9421    0.9561    0.9490      1617

all (micro avg.)     0.8791    0.9037    0.8912      5648


** Best ** model scores - run 1
                  precision    recall  f1-score   support

             LOC     0.9135    0.9311    0.9222      1668
            MISC     0.8028    0.8120    0.8074       702
             ORG     0.8401    0.8856    0.8623      1661
             PER     0.9538    0.9573    0.9556      1617

all (micro avg.)     0.8890    0.9104    0.8996      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9064    0.9314    0.9187      1668
            MISC     0.7907    0.7964    0.7935       702
             ORG     0.8392    0.8794    0.8588      1661
             PER     0.9484    0.9557    0.9520      1617

all (micro avg.)     0.8838    0.9063    0.8949




> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_CNN --embedding glove-840B --fold-count 10 --train-with-validation-set

training runtime: 41234.934 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 89.90
                  precision    recall  f1-score   support

             LOC     0.9048    0.9347    0.9195      1668
            MISC     0.7922    0.8091    0.8006       702
             ORG     0.8590    0.8766    0.8677      1661
             PER     0.9463    0.9592    0.9527      1617

all (micro avg.)     0.8892    0.9090    0.8990      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 89.79
                  precision    recall  f1-score   support

             LOC     0.9157    0.9311    0.9233      1668
            MISC     0.7949    0.7949    0.7949       702
             ORG     0.8426    0.8862    0.8638      1661
             PER     0.9479    0.9561    0.9520      1617

all (micro avg.)     0.8880    0.9081    0.8979      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 89.69
                  precision    recall  f1-score   support

             LOC     0.9029    0.9311    0.9168      1668
            MISC     0.8026    0.7934    0.7980       702
             ORG     0.8481    0.8838    0.8656      1661
             PER     0.9456    0.9573    0.9514      1617

all (micro avg.)     0.8865    0.9076    0.8969      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 90.07
                  precision    recall  f1-score   support

             LOC     0.9076    0.9359    0.9215      1668
            MISC     0.8035    0.7920    0.7977       702
             ORG     0.8560    0.8874    0.8714      1661
             PER     0.9480    0.9592    0.9536      1617

all (micro avg.)     0.8912    0.9104    0.9007      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 89.73
                  precision    recall  f1-score   support

             LOC     0.9008    0.9365    0.9183      1668
            MISC     0.7919    0.8077    0.7997       702
             ORG     0.8558    0.8790    0.8672      1661
             PER     0.9427    0.9561    0.9493      1617

all (micro avg.)     0.8860    0.9092    0.8974      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 89.94
                  precision    recall  f1-score   support

             LOC     0.9028    0.9406    0.9213      1668
            MISC     0.7938    0.8006    0.7972       702
             ORG     0.8627    0.8742    0.8684      1661
             PER     0.9491    0.9567    0.9529      1617

all (micro avg.)     0.8908    0.9083    0.8994      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 90.13
                  precision    recall  f1-score   support

             LOC     0.9140    0.9305    0.9222      1668
            MISC     0.7986    0.7963    0.7974       702
             ORG     0.8564    0.8940    0.8748      1661
             PER     0.9479    0.9567    0.9523      1617

all (micro avg.)     0.8923    0.9106    0.9013      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 89.83
                  precision    recall  f1-score   support

             LOC     0.9075    0.9293    0.9182      1668
            MISC     0.7887    0.7977    0.7932       702
             ORG     0.8540    0.8838    0.8686      1661
             PER     0.9448    0.9629    0.9538      1617

all (micro avg.)     0.8876    0.9092    0.8983      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 89.71
                  precision    recall  f1-score   support

             LOC     0.9115    0.9329    0.9221      1668
            MISC     0.7980    0.7877    0.7928       702
             ORG     0.8474    0.8856    0.8661      1661
             PER     0.9409    0.9555    0.9481      1617

all (micro avg.)     0.8870    0.9074    0.8971      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 89.76
                  precision    recall  f1-score   support

             LOC     0.9060    0.9359    0.9207      1668
            MISC     0.7957    0.7991    0.7974       702
             ORG     0.8488    0.8790    0.8636      1661
             PER     0.9490    0.9555    0.9522      1617

all (micro avg.)     0.8876    0.9078    0.8976      5648

----------------------------------------------------------------------

** Worst ** model scores - run 2
                  precision    recall  f1-score   support

             LOC     0.9029    0.9311    0.9168      1668
            MISC     0.8026    0.7934    0.7980       702
             ORG     0.8481    0.8838    0.8656      1661
             PER     0.9456    0.9573    0.9514      1617

all (micro avg.)     0.8865    0.9076    0.8969      5648


** Best ** model scores - run 6
                  precision    recall  f1-score   support

             LOC     0.9140    0.9305    0.9222      1668
            MISC     0.7986    0.7963    0.7974       702
             ORG     0.8564    0.8940    0.8748      1661
             PER     0.9479    0.9567    0.9523      1617

all (micro avg.)     0.8923    0.9106    0.9013      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9074    0.9338    0.9204      1668
            MISC     0.7960    0.7979    0.7969       702
             ORG     0.8531    0.8830    0.8677      1661
             PER     0.9462    0.9575    0.9518      1617

all (micro avg.)     0.8886    0.9087    0.8985  



> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_CNN_CRF --embedding glove-840B --fold-count 10

training runtime: 25486.061 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 90.39
                  precision    recall  f1-score   support

             LOC     0.9256    0.9323    0.9289      1668
            MISC     0.8047    0.7749    0.7896       702
             ORG     0.8545    0.9019    0.8776      1661
             PER     0.9588    0.9505    0.9547      1617

all (micro avg.)     0.8988    0.9090    0.9039      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 90.46
                  precision    recall  f1-score   support

             LOC     0.9161    0.9365    0.9262      1668
            MISC     0.8056    0.7792    0.7922       702
             ORG     0.8643    0.8977    0.8807      1661
             PER     0.9521    0.9579    0.9550      1617

all (micro avg.)     0.8977    0.9117    0.9046      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 90.20
                  precision    recall  f1-score   support

             LOC     0.9123    0.9359    0.9239      1668
            MISC     0.8074    0.7764    0.7916       702
             ORG     0.8608    0.8862    0.8733      1661
             PER     0.9510    0.9604    0.9557      1617

all (micro avg.)     0.8956    0.9085    0.9020      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 90.81
                  precision    recall  f1-score   support

             LOC     0.9335    0.9257    0.9296      1668
            MISC     0.8169    0.8006    0.8086       702
             ORG     0.8730    0.8983    0.8855      1661
             PER     0.9468    0.9573    0.9520      1617

all (micro avg.)     0.9050    0.9111    0.9081      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 90.69
                  precision    recall  f1-score   support

             LOC     0.9122    0.9341    0.9230      1668
            MISC     0.8070    0.7920    0.7994       702
             ORG     0.8729    0.8970    0.8848      1661
             PER     0.9621    0.9567    0.9594      1617

all (micro avg.)     0.9018    0.9120    0.9069      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 90.77
                  precision    recall  f1-score   support

             LOC     0.9096    0.9412    0.9252      1668
            MISC     0.8190    0.7863    0.8023       702
             ORG     0.8818    0.8940    0.8879      1661
             PER     0.9503    0.9586    0.9544      1617

all (micro avg.)     0.9024    0.9131    0.9077      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 91.23
                  precision    recall  f1-score   support

             LOC     0.9250    0.9388    0.9319      1668
            MISC     0.8245    0.7963    0.8101       702
             ORG     0.8862    0.8958    0.8910      1661
             PER     0.9540    0.9610    0.9575      1617

all (micro avg.)     0.9098    0.9148    0.9123      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 90.61
                  precision    recall  f1-score   support

             LOC     0.9181    0.9347    0.9263      1668
            MISC     0.8112    0.7835    0.7971       702
             ORG     0.8638    0.8977    0.8804      1661
             PER     0.9586    0.9586    0.9586      1617

all (micro avg.)     0.9005    0.9118    0.9061      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 90.24
                  precision    recall  f1-score   support

             LOC     0.9182    0.9287    0.9234      1668
            MISC     0.8183    0.7892    0.8035       702
             ORG     0.8540    0.8946    0.8739      1661
             PER     0.9616    0.9450    0.9532      1617

all (micro avg.)     0.8988    0.9060    0.9024      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 91.05
                  precision    recall  f1-score   support

             LOC     0.9192    0.9412    0.9301      1668
            MISC     0.8243    0.8020    0.8130       702
             ORG     0.8759    0.8964    0.8860      1661
             PER     0.9517    0.9623    0.9569      1617

all (micro avg.)     0.9043    0.9168    0.9105      5648

----------------------------------------------------------------------

** Worst ** model scores - run 2
                  precision    recall  f1-score   support

             LOC     0.9123    0.9359    0.9239      1668
            MISC     0.8074    0.7764    0.7916       702
             ORG     0.8608    0.8862    0.8733      1661
             PER     0.9510    0.9604    0.9557      1617

all (micro avg.)     0.8956    0.9085    0.9020      5648


** Best ** model scores - run 6
                  precision    recall  f1-score   support

             LOC     0.9250    0.9388    0.9319      1668
            MISC     0.8245    0.7963    0.8101       702
             ORG     0.8862    0.8958    0.8910      1661
             PER     0.9540    0.9610    0.9575      1617

all (micro avg.)     0.9098    0.9148    0.9123      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9190    0.9349    0.9268      1668
            MISC     0.8139    0.7880    0.8007       702
             ORG     0.8687    0.8960    0.8821      1661
             PER     0.9547    0.9568    0.9557      1617

all (micro avg.)     0.9015    0.9115    0.9064 


> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_CNN_CRF --embedding glove-840B --fold-count 10 --train-with-validation-set

training runtime: 31835.516 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 90.99
                  precision    recall  f1-score   support

             LOC     0.8990    0.9442    0.9211      1668
            MISC     0.8084    0.7991    0.8037       702
             ORG     0.9034    0.8838    0.8935      1661
             PER     0.9537    0.9672    0.9604      1617

all (micro avg.)     0.9049    0.9150    0.9099      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 91.04
                  precision    recall  f1-score   support

             LOC     0.9243    0.9376    0.9310      1668
            MISC     0.8275    0.8134    0.8204       702
             ORG     0.8768    0.8910    0.8838      1661
             PER     0.9454    0.9641    0.9547      1617

all (micro avg.)     0.9047    0.9161    0.9104      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 91.17
                  precision    recall  f1-score   support

             LOC     0.9254    0.9371    0.9312      1668
            MISC     0.8158    0.7949    0.8052       702
             ORG     0.8892    0.8989    0.8940      1661
             PER     0.9526    0.9579    0.9553      1617

all (micro avg.)     0.9093    0.9141    0.9117      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 91.38
                  precision    recall  f1-score   support

             LOC     0.9424    0.9317    0.9370      1668
            MISC     0.8097    0.8120    0.8108       702
             ORG     0.8859    0.9019    0.8938      1661
             PER     0.9433    0.9672    0.9551      1617

all (micro avg.)     0.9095    0.9182    0.9138      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 90.80
                  precision    recall  f1-score   support

             LOC     0.9016    0.9448    0.9227      1668
            MISC     0.8253    0.8006    0.8127       702
             ORG     0.8892    0.8886    0.8889      1661
             PER     0.9502    0.9555    0.9528      1617

all (micro avg.)     0.9027    0.9134    0.9080      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 90.79
                  precision    recall  f1-score   support

             LOC     0.9424    0.9317    0.9370      1668
            MISC     0.8171    0.8020    0.8095       702
             ORG     0.8487    0.9085    0.8776      1661
             PER     0.9593    0.9468    0.9530      1617

all (micro avg.)     0.9028    0.9131    0.9079      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 90.62
                  precision    recall  f1-score   support

             LOC     0.9178    0.9376    0.9276      1668
            MISC     0.8343    0.7963    0.8149       702
             ORG     0.8594    0.8977    0.8781      1661
             PER     0.9490    0.9549    0.9519      1617

all (micro avg.)     0.8992    0.9132    0.9062      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 90.91
                  precision    recall  f1-score   support

             LOC     0.9267    0.9323    0.9295      1668
            MISC     0.8268    0.8091    0.8179       702
             ORG     0.8650    0.9025    0.8833      1661
             PER     0.9542    0.9542    0.9542      1617

all (micro avg.)     0.9038    0.9145    0.9091      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 91.28
                  precision    recall  f1-score   support

             LOC     0.9292    0.9365    0.9328      1668
            MISC     0.8210    0.8034    0.8121       702
             ORG     0.8829    0.8989    0.8908      1661
             PER     0.9614    0.9549    0.9581      1617

all (micro avg.)     0.9114    0.9141    0.9128      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 90.86
                  precision    recall  f1-score   support

             LOC     0.9168    0.9376    0.9271      1668
            MISC     0.8088    0.8077    0.8083       702
             ORG     0.8811    0.8874    0.8842      1661
             PER     0.9512    0.9641    0.9576      1617

all (micro avg.)     0.9030    0.9143    0.9086      5648

----------------------------------------------------------------------

** Worst ** model scores - run 6
                  precision    recall  f1-score   support

             LOC     0.9178    0.9376    0.9276      1668
            MISC     0.8343    0.7963    0.8149       702
             ORG     0.8594    0.8977    0.8781      1661
             PER     0.9490    0.9549    0.9519      1617

all (micro avg.)     0.8992    0.9132    0.9062      5648


** Best ** model scores - run 3
                  precision    recall  f1-score   support

             LOC     0.9424    0.9317    0.9370      1668
            MISC     0.8097    0.8120    0.8108       702
             ORG     0.8859    0.9019    0.8938      1661
             PER     0.9433    0.9672    0.9551      1617

all (micro avg.)     0.9095    0.9182    0.9138      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9226    0.9371    0.9297      1668
            MISC     0.8195    0.8038    0.8115       702
             ORG     0.8781    0.8959    0.8868      1661
             PER     0.9520    0.9587    0.9553      1617

all (micro avg.)     0.9051    0.9146    0.9098



> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_CRF_CASING --embedding glove-840B --fold-count 10

training runtime: 30474.856 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 90.77
                  precision    recall  f1-score   support

             LOC     0.9181    0.9341    0.9260      1668
            MISC     0.7864    0.8077    0.7969       702
             ORG     0.8905    0.8766    0.8835      1661
             PER     0.9600    0.9641    0.9620      1617

all (micro avg.)     0.9054    0.9101    0.9077      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 91.11
                  precision    recall  f1-score   support

             LOC     0.9221    0.9365    0.9292      1668
            MISC     0.8066    0.8020    0.8043       702
             ORG     0.8993    0.8820    0.8906      1661
             PER     0.9524    0.9660    0.9592      1617

all (micro avg.)     0.9101    0.9122    0.9111      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 91.22
                  precision    recall  f1-score   support

             LOC     0.9137    0.9394    0.9264      1668
            MISC     0.8215    0.8063    0.8138       702
             ORG     0.9039    0.8832    0.8934      1661
             PER     0.9552    0.9623    0.9587      1617

all (micro avg.)     0.9116    0.9129    0.9122      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 91.31
                  precision    recall  f1-score   support

             LOC     0.9300    0.9323    0.9311      1668
            MISC     0.8097    0.8063    0.8080       702
             ORG     0.8854    0.8977    0.8915      1661
             PER     0.9640    0.9610    0.9625      1617

all (micro avg.)     0.9116    0.9147    0.9131      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 90.41
                  precision    recall  f1-score   support

             LOC     0.9294    0.9233    0.9263      1668
            MISC     0.7988    0.7863    0.7925       702
             ORG     0.8575    0.9061    0.8811      1661
             PER     0.9646    0.9437    0.9540      1617

all (micro avg.)     0.9011    0.9070    0.9041      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 91.01
                  precision    recall  f1-score   support

             LOC     0.9270    0.9371    0.9320      1668
            MISC     0.8099    0.7892    0.7994       702
             ORG     0.8780    0.8928    0.8854      1661
             PER     0.9599    0.9610    0.9604      1617

all (micro avg.)     0.9077    0.9125    0.9101      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 90.78
                  precision    recall  f1-score   support

             LOC     0.9269    0.9275    0.9272      1668
            MISC     0.8239    0.7863    0.8047       702
             ORG     0.8726    0.8910    0.8817      1661
             PER     0.9580    0.9592    0.9586      1617

all (micro avg.)     0.9073    0.9083    0.9078      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 91.09
                  precision    recall  f1-score   support

             LOC     0.9229    0.9394    0.9311      1668
            MISC     0.7933    0.8091    0.8011       702
             ORG     0.8958    0.8802    0.8879      1661
             PER     0.9616    0.9610    0.9613      1617

all (micro avg.)     0.9097    0.9120    0.9109      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 91.10
                  precision    recall  f1-score   support

             LOC     0.9200    0.9311    0.9255      1668
            MISC     0.8274    0.7991    0.8130       702
             ORG     0.8829    0.8940    0.8884      1661
             PER     0.9645    0.9579    0.9612      1617

all (micro avg.)     0.9105    0.9115    0.9110      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 91.40
                  precision    recall  f1-score   support

             LOC     0.9228    0.9382    0.9304      1668
            MISC     0.8260    0.7977    0.8116       702
             ORG     0.8948    0.8910    0.8929      1661
             PER     0.9594    0.9647    0.9621      1617

all (micro avg.)     0.9135    0.9145    0.9140      5648

----------------------------------------------------------------------

** Worst ** model scores - run 4
                  precision    recall  f1-score   support

             LOC     0.9294    0.9233    0.9263      1668
            MISC     0.7988    0.7863    0.7925       702
             ORG     0.8575    0.9061    0.8811      1661
             PER     0.9646    0.9437    0.9540      1617

all (micro avg.)     0.9011    0.9070    0.9041      5648


** Best ** model scores - run 9
                  precision    recall  f1-score   support

             LOC     0.9228    0.9382    0.9304      1668
            MISC     0.8260    0.7977    0.8116       702
             ORG     0.8948    0.8910    0.8929      1661
             PER     0.9594    0.9647    0.9621      1617

all (micro avg.)     0.9135    0.9145    0.9140      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9233    0.9339    0.9285      1668
            MISC     0.8104    0.7990    0.8045       702
             ORG     0.8861    0.8895    0.8877      1661
             PER     0.9600    0.9601    0.9600      1617

all (micro avg.)     0.9089    0.9116    0.9102    




> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BERT --transformer bert-base-cased --fold-count 10


training runtime: 16152.433 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights0.hdf5
    f1: 91.15
    precision: 90.33
    recall: 91.98

------------------------ fold 1 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights1.hdf5
    f1: 91.27
    precision: 90.50
    recall: 92.05

------------------------ fold 2 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights2.hdf5
    f1: 91.20
    precision: 90.33
    recall: 92.09

------------------------ fold 3 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights3.hdf5
    f1: 90.89
    precision: 89.90
    recall: 91.89

------------------------ fold 4 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights4.hdf5
    f1: 91.00
    precision: 90.16
    recall: 91.86

------------------------ fold 5 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights5.hdf5
    f1: 91.13
    precision: 90.40
    recall: 91.87

------------------------ fold 6 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights6.hdf5
    f1: 91.09
    precision: 90.05
    recall: 92.16

------------------------ fold 7 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights7.hdf5
    f1: 91.27
    precision: 90.21
    recall: 92.35

------------------------ fold 8 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights8.hdf5
    f1: 91.56
    precision: 90.82
    recall: 92.32

------------------------ fold 9 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights9.hdf5
    f1: 91.33
    precision: 90.39
    recall: 92.28
----------------------------------------------------------------------

** Worst ** model scores - run 3
                  precision    recall  f1-score   support

             LOC     0.9302    0.9263    0.9282      1668
            MISC     0.7683    0.8362    0.8008       702
             ORG     0.8740    0.9019    0.8877      1661
             PER     0.9547    0.9647    0.9597      1617

all (micro avg.)     0.8990    0.9189    0.9089      5648


** Best ** model scores - run 8
                  precision    recall  f1-score   support

             LOC     0.9338    0.9388    0.9363      1668
            MISC     0.7791    0.8291    0.8033       702
             ORG     0.8847    0.9103    0.8973      1661
             PER     0.9664    0.9610    0.9637      1617

all (micro avg.)     0.9082    0.9232    0.9156      5648

loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights8.hdf5
----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9311    0.9326    0.9319      1668
            MISC     0.7728    0.8268    0.7988       702
             ORG     0.8774    0.9080    0.8924      1661
             PER     0.9620    0.9627    0.9624      1617

all (micro avg.)     0.9031    0.9208    0.9119




> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BERT --transformer bert-base-cased --fold-count 10 --train-with-validation-set

training runtime: 18114.053 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights0.hdf5
    f1: 91.58
    precision: 90.69
    recall: 92.49

------------------------ fold 1 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights1.hdf5
    f1: 91.38
    precision: 90.53
    recall: 92.25

------------------------ fold 2 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights2.hdf5
    f1: 91.20
    precision: 90.21
    recall: 92.21

------------------------ fold 3 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights3.hdf5
    f1: 91.50
    precision: 90.55
    recall: 92.48

------------------------ fold 4 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights4.hdf5
    f1: 91.75
    precision: 90.92
    recall: 92.60

------------------------ fold 5 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights5.hdf5
    f1: 91.63
    precision: 90.90
    recall: 92.37

------------------------ fold 6 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights6.hdf5
    f1: 91.64
    precision: 90.91
    recall: 92.39

------------------------ fold 7 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights7.hdf5
    f1: 91.68
    precision: 90.88
    recall: 92.49

------------------------ fold 8 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights8.hdf5
    f1: 91.40
    precision: 90.56
    recall: 92.25

------------------------ fold 9 --------------------------------------
__________________________________________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights9.hdf5
    f1: 91.30
    precision: 90.27
    recall: 92.35
----------------------------------------------------------------------

** Worst ** model scores - run 2
                  precision    recall  f1-score   support

             LOC     0.9209    0.9353    0.9280      1668
            MISC     0.7788    0.8276    0.8025       702
             ORG     0.8772    0.9121    0.8943      1661
             PER     0.9664    0.9598    0.9631      1617

all (micro avg.)     0.9021    0.9221    0.9120      5648


** Best ** model scores - run 4
                  precision    recall  f1-score   support

             LOC     0.9291    0.9353    0.9322      1668
            MISC     0.7973    0.8405    0.8183       702
             ORG     0.8883    0.9145    0.9012      1661
             PER     0.9618    0.9654    0.9636      1617

all (micro avg.)     0.9092    0.9260    0.9175      5648

loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights4.hdf5
----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9289    0.9338    0.9313      1668
            MISC     0.7899    0.8278    0.8083       702
             ORG     0.8798    0.9158    0.8974      1661
             PER     0.9649    0.9636    0.9643      1617

all (micro avg.)     0.9064    0.9239    0.9151




> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BERT_CRF --transformer bert-base-cased --fold-count 10

training runtime: 19890.326 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights0.hdf5
    f1: 91.24
    precision: 90.59
    recall: 91.89

------------------------ fold 1 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights1.hdf5
    f1: 91.37
    precision: 90.57
    recall: 92.17

------------------------ fold 2 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights2.hdf5
    f1: 91.50
    precision: 90.83
    recall: 92.19

------------------------ fold 3 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights3.hdf5
    f1: 91.64
    precision: 90.85
    recall: 92.44

------------------------ fold 4 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights4.hdf5
    f1: 91.00
    precision: 90.08
    recall: 91.94

------------------------ fold 5 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights5.hdf5
    f1: 90.92
    precision: 89.85
    recall: 92.01

------------------------ fold 6 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights6.hdf5
    f1: 91.30
    precision: 90.49
    recall: 92.12

------------------------ fold 7 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights7.hdf5
    f1: 91.26
    precision: 90.35
    recall: 92.19

------------------------ fold 8 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights8.hdf5
    f1: 91.03
    precision: 90.20
    recall: 91.87

------------------------ fold 9 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights9.hdf5
    f1: 91.28
    precision: 90.47
    recall: 92.10
----------------------------------------------------------------------

** Worst ** model scores - run 5
                  precision    recall  f1-score   support

             LOC     0.9297    0.9353    0.9325      1668
            MISC     0.7738    0.8234    0.7978       702
             ORG     0.8647    0.9079    0.8858      1661
             PER     0.9604    0.9592    0.9598      1617

all (micro avg.)     0.8985    0.9201    0.9092      5648


** Best ** model scores - run 3
                  precision    recall  f1-score   support

             LOC     0.9319    0.9347    0.9333      1668
            MISC     0.7908    0.8348    0.8122       702
             ORG     0.8806    0.9145    0.8972      1661
             PER     0.9683    0.9629    0.9656      1617

all (micro avg.)     0.9085    0.9244    0.9164      5648

loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF/model_weights3.hdf5
----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9308    0.9334    0.9321      1668
            MISC     0.7792    0.8271    0.8024       702
             ORG     0.8781    0.9087    0.8931      1661
             PER     0.9625    0.9615    0.9620      1617

all (micro avg.)     0.9043    0.9209    0.9125 




> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BERT_CRF_CHAR --transformer bert-base-cased --fold-count 10

training runtime: 29477.754 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights0.hdf5
    f1: 91.04
    precision: 90.37
    recall: 91.71

------------------------ fold 1 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights1.hdf5
    f1: 91.23
    precision: 90.35
    recall: 92.14

------------------------ fold 2 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights2.hdf5
    f1: 90.72
    precision: 89.66
    recall: 91.80

------------------------ fold 3 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights3.hdf5
    f1: 90.65
    precision: 89.72
    recall: 91.61

------------------------ fold 4 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights4.hdf5
    f1: 91.28
    precision: 90.48
    recall: 92.09

------------------------ fold 5 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights5.hdf5
    f1: 90.40
    precision: 89.43
    recall: 91.40

------------------------ fold 6 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights6.hdf5
    f1: 91.07
    precision: 90.20
    recall: 91.94

------------------------ fold 7 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights7.hdf5
    f1: 91.53
    precision: 90.73
    recall: 92.35

------------------------ fold 8 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights8.hdf5
    f1: 90.40
    precision: 89.13
    recall: 91.71

------------------------ fold 9 --------------------------------------
_________________________________________________________________
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights9.hdf5
    f1: 91.27
    precision: 90.54
    recall: 92.01
----------------------------------------------------------------------

** Worst ** model scores - run 8
                  precision    recall  f1-score   support

             LOC     0.9202    0.9335    0.9268      1668
            MISC     0.6918    0.8376    0.7577       702
             ORG     0.8877    0.8946    0.8912      1661
             PER     0.9706    0.9579    0.9642      1617

all (micro avg.)     0.8913    0.9171    0.9040      5648


** Best ** model scores - run 7
                  precision    recall  f1-score   support

             LOC     0.9238    0.9371    0.9304      1668
            MISC     0.7605    0.8276    0.7926       702
             ORG     0.9012    0.9121    0.9066      1661
             PER     0.9659    0.9629    0.9644      1617

all (micro avg.)     0.9073    0.9235    0.9153      5648

loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT_CRF_CHAR/model_weights7.hdf5
----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9258    0.9327    0.9292      1668
            MISC     0.7543    0.8274    0.7889       702
             ORG     0.8819    0.9076    0.8945      1661
             PER     0.9651    0.9555    0.9603      1617

all (micro avg.)     0.9006    0.9188    0.9096   

