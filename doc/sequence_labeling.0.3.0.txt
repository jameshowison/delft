



python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_CRF --embedding glove-840B --fold-count 10

training runtime: 29956.487 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 91.01
                  precision    recall  f1-score   support

             LOC     0.9153    0.9394    0.9272      1668
            MISC     0.8023    0.7977    0.8000       702
             ORG     0.8982    0.8820    0.8900      1661
             PER     0.9610    0.9598    0.9604      1617

all (micro avg.)     0.9095    0.9108    0.9101      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 91.38
                  precision    recall  f1-score   support

             LOC     0.9270    0.9371    0.9320      1668
            MISC     0.8127    0.8034    0.8080       702
             ORG     0.8931    0.8898    0.8914      1661
             PER     0.9606    0.9660    0.9633      1617

all (micro avg.)     0.9127    0.9148    0.9138      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 90.97
                  precision    recall  f1-score   support

             LOC     0.9204    0.9359    0.9281      1668
            MISC     0.8107    0.7806    0.7954       702
             ORG     0.8852    0.8910    0.8881      1661
             PER     0.9657    0.9579    0.9618      1617

all (micro avg.)     0.9097    0.9097    0.9097      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 90.97
                  precision    recall  f1-score   support

             LOC     0.9110    0.9329    0.9218      1668
            MISC     0.8290    0.7806    0.8041       702
             ORG     0.8828    0.8983    0.8905      1661
             PER     0.9628    0.9604    0.9616      1617

all (micro avg.)     0.9078    0.9117    0.9097      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 90.92
                  precision    recall  f1-score   support

             LOC     0.9149    0.9347    0.9247      1668
            MISC     0.8356    0.7892    0.8117       702
             ORG     0.8809    0.8904    0.8856      1661
             PER     0.9535    0.9629    0.9582      1617

all (micro avg.)     0.9067    0.9117    0.9092      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 91.25
                  precision    recall  f1-score   support

             LOC     0.9189    0.9371    0.9279      1668
            MISC     0.8076    0.8191    0.8133       702
             ORG     0.8934    0.8880    0.8907      1661
             PER     0.9600    0.9641    0.9620      1617

all (micro avg.)     0.9093    0.9157    0.9125      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 91.03
                  precision    recall  f1-score   support

             LOC     0.9162    0.9371    0.9265      1668
            MISC     0.8109    0.8063    0.8086       702
             ORG     0.8879    0.8826    0.8853      1661
             PER     0.9664    0.9604    0.9634      1617

all (micro avg.)     0.9092    0.9115    0.9103      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 91.07
                  precision    recall  f1-score   support

             LOC     0.9233    0.9376    0.9304      1668
            MISC     0.8126    0.8091    0.8108       702
             ORG     0.8826    0.8874    0.8850      1661
             PER     0.9604    0.9598    0.9601      1617

all (micro avg.)     0.9083    0.9132    0.9107      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 90.90
                  precision    recall  f1-score   support

             LOC     0.9108    0.9365    0.9234      1668
            MISC     0.8129    0.8048    0.8089       702
             ORG     0.8964    0.8808    0.8886      1661
             PER     0.9551    0.9604    0.9578      1617

all (micro avg.)     0.9074    0.9106    0.9090      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 90.78
                  precision    recall  f1-score   support

             LOC     0.9198    0.9347    0.9271      1668
            MISC     0.8200    0.7721    0.7953       702
             ORG     0.8729    0.8928    0.8827      1661
             PER     0.9616    0.9604    0.9610      1617

all (micro avg.)     0.9060    0.9095    0.9078      5648

----------------------------------------------------------------------

** Worst ** model scores - run 9
                  precision    recall  f1-score   support

             LOC     0.9198    0.9347    0.9271      1668
            MISC     0.8200    0.7721    0.7953       702
             ORG     0.8729    0.8928    0.8827      1661
             PER     0.9616    0.9604    0.9610      1617

all (micro avg.)     0.9060    0.9095    0.9078      5648


** Best ** model scores - run 1
                  precision    recall  f1-score   support

             LOC     0.9270    0.9371    0.9320      1668
            MISC     0.8127    0.8034    0.8080       702
             ORG     0.8931    0.8898    0.8914      1661
             PER     0.9606    0.9660    0.9633      1617

all (micro avg.)     0.9127    0.9148    0.9138      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9178    0.9363    0.9269      1668
            MISC     0.8154    0.7963    0.8056       702
             ORG     0.8873    0.8883    0.8878      1661
             PER     0.9607    0.9612    0.9610      1617

all (micro avg.)     0.9087    0.9119    0.9103






python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidGRU_CRF --embedding glove-840B --fold-count 10

training runtime: 42159.586 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 90.37
                  precision    recall  f1-score   support

             LOC     0.9370    0.9269    0.9319      1668
            MISC     0.7903    0.7621    0.7759       702
             ORG     0.8590    0.8983    0.8782      1661
             PER     0.9471    0.9641    0.9556      1617

all (micro avg.)     0.8988    0.9086    0.9037      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 90.55
                  precision    recall  f1-score   support

             LOC     0.9275    0.9353    0.9313      1668
            MISC     0.7724    0.7977    0.7849       702
             ORG     0.8850    0.8850    0.8850      1661
             PER     0.9409    0.9641    0.9524      1617

all (micro avg.)     0.8994    0.9117    0.9055      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 89.91
                  precision    recall  f1-score   support

             LOC     0.9127    0.9341    0.9233      1668
            MISC     0.7988    0.7635    0.7808       702
             ORG     0.8616    0.8772    0.8693      1661
             PER     0.9476    0.9617    0.9546      1617

all (micro avg.)     0.8942    0.9040    0.8991      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 90.32
                  precision    recall  f1-score   support

             LOC     0.9211    0.9305    0.9257      1668
            MISC     0.7806    0.7806    0.7806       702
             ORG     0.8782    0.8772    0.8777      1661
             PER     0.9547    0.9635    0.9591      1617

all (micro avg.)     0.9008    0.9056    0.9032      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 89.91
                  precision    recall  f1-score   support

             LOC     0.8926    0.9365    0.9140      1668
            MISC     0.8063    0.7707    0.7881       702
             ORG     0.8991    0.8633    0.8808      1661
             PER     0.9367    0.9604    0.9484      1617

all (micro avg.)     0.8971    0.9012    0.8991      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 90.22
                  precision    recall  f1-score   support

             LOC     0.9282    0.9305    0.9293      1668
            MISC     0.7531    0.7821    0.7673       702
             ORG     0.8888    0.8802    0.8845      1661
             PER     0.9333    0.9697    0.9512      1617

all (micro avg.)     0.8961    0.9085    0.9022      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 90.49
                  precision    recall  f1-score   support

             LOC     0.9135    0.9365    0.9248      1668
            MISC     0.7816    0.7849    0.7832       702
             ORG     0.8955    0.8772    0.8863      1661
             PER     0.9477    0.9635    0.9555      1617

all (micro avg.)     0.9019    0.9079    0.9049      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 89.90
                  precision    recall  f1-score   support

             LOC     0.9070    0.9353    0.9209      1668
            MISC     0.7523    0.8048    0.7777       702
             ORG     0.8846    0.8766    0.8806      1661
             PER     0.9357    0.9623    0.9488      1617

all (micro avg.)     0.8888    0.9095    0.8990      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 90.09
                  precision    recall  f1-score   support

             LOC     0.9105    0.9329    0.9215      1668
            MISC     0.7874    0.7650    0.7760       702
             ORG     0.8844    0.8844    0.8844      1661
             PER     0.9341    0.9641    0.9489      1617

all (micro avg.)     0.8951    0.9067    0.9009      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 89.96
                  precision    recall  f1-score   support

             LOC     0.9045    0.9365    0.9202      1668
            MISC     0.8259    0.7635    0.7935       702
             ORG     0.8725    0.8772    0.8748      1661
             PER     0.9360    0.9586    0.9471      1617

all (micro avg.)     0.8953    0.9039    0.8996      5648

----------------------------------------------------------------------

** Worst ** model scores - run 7
                  precision    recall  f1-score   support

             LOC     0.9070    0.9353    0.9209      1668
            MISC     0.7523    0.8048    0.7777       702
             ORG     0.8846    0.8766    0.8806      1661
             PER     0.9357    0.9623    0.9488      1617

all (micro avg.)     0.8888    0.9095    0.8990      5648


** Best ** model scores - run 1
                  precision    recall  f1-score   support

             LOC     0.9275    0.9353    0.9313      1668
            MISC     0.7724    0.7977    0.7849       702
             ORG     0.8850    0.8850    0.8850      1661
             PER     0.9409    0.9641    0.9524      1617

all (micro avg.)     0.8994    0.9117    0.9055      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9154    0.9335    0.9243      1668
            MISC     0.7849    0.7775    0.7808       702
             ORG     0.8809    0.8797    0.8802      1661
             PER     0.9414    0.9632    0.9521      1617

all (micro avg.)     0.8967    0.9068    0.9017 




python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BidLSTM_CNN --embedding glove-840B --fold-count 10

training runtime: 28500.657 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
    f1 (micro): 89.64
                  precision    recall  f1-score   support

             LOC     0.9118    0.9239    0.9178      1668
            MISC     0.7991    0.7877    0.7934       702
             ORG     0.8385    0.8910    0.8640      1661
             PER     0.9502    0.9555    0.9528      1617

all (micro avg.)     0.8867    0.9063    0.8964      5648


------------------------ fold 1 --------------------------------------
    f1 (micro): 89.96
                  precision    recall  f1-score   support

             LOC     0.9135    0.9311    0.9222      1668
            MISC     0.8028    0.8120    0.8074       702
             ORG     0.8401    0.8856    0.8623      1661
             PER     0.9538    0.9573    0.9556      1617

all (micro avg.)     0.8890    0.9104    0.8996      5648


------------------------ fold 2 --------------------------------------
    f1 (micro): 89.48
                  precision    recall  f1-score   support

             LOC     0.9091    0.9293    0.9191      1668
            MISC     0.7884    0.7963    0.7923       702
             ORG     0.8281    0.8814    0.8539      1661
             PER     0.9574    0.9579    0.9577      1617

all (micro avg.)     0.8831    0.9069    0.8948      5648


------------------------ fold 3 --------------------------------------
    f1 (micro): 89.56
                  precision    recall  f1-score   support

             LOC     0.9059    0.9347    0.9200      1668
            MISC     0.8000    0.7863    0.7931       702
             ORG     0.8472    0.8712    0.8590      1661
             PER     0.9473    0.9567    0.9520      1617

all (micro avg.)     0.8875    0.9039    0.8956      5648


------------------------ fold 4 --------------------------------------
    f1 (micro): 89.12
                  precision    recall  f1-score   support

             LOC     0.8959    0.9341    0.9146      1668
            MISC     0.7732    0.7963    0.7846       702
             ORG     0.8462    0.8675    0.8567      1661
             PER     0.9421    0.9561    0.9490      1617

all (micro avg.)     0.8791    0.9037    0.8912      5648


------------------------ fold 5 --------------------------------------
    f1 (micro): 89.19
                  precision    recall  f1-score   support

             LOC     0.9060    0.9299    0.9178      1668
            MISC     0.7717    0.7849    0.7782       702
             ORG     0.8342    0.8814    0.8571      1661
             PER     0.9534    0.9493    0.9513      1617

all (micro avg.)     0.8808    0.9032    0.8919      5648


------------------------ fold 6 --------------------------------------
    f1 (micro): 89.19
                  precision    recall  f1-score   support

             LOC     0.9017    0.9347    0.9179      1668
            MISC     0.7880    0.8048    0.7963       702
             ORG     0.8373    0.8675    0.8522      1661
             PER     0.9430    0.9524    0.9477      1617

all (micro avg.)     0.8802    0.9039    0.8919      5648


------------------------ fold 7 --------------------------------------
    f1 (micro): 89.48
                  precision    recall  f1-score   support

             LOC     0.9124    0.9305    0.9213      1668
            MISC     0.8011    0.7977    0.7994       702
             ORG     0.8281    0.8874    0.8567      1661
             PER     0.9432    0.9542    0.9487      1617

all (micro avg.)     0.8819    0.9081    0.8948      5648


------------------------ fold 8 --------------------------------------
    f1 (micro): 89.61
                  precision    recall  f1-score   support

             LOC     0.9001    0.9347    0.9171      1668
            MISC     0.7954    0.7920    0.7937       702
             ORG     0.8474    0.8796    0.8632      1661
             PER     0.9485    0.9567    0.9526      1617

all (micro avg.)     0.8854    0.9070    0.8961      5648


------------------------ fold 9 --------------------------------------
    f1 (micro): 89.68
                  precision    recall  f1-score   support

             LOC     0.9071    0.9311    0.9189      1668
            MISC     0.7872    0.8063    0.7966       702
             ORG     0.8453    0.8814    0.8630      1661
             PER     0.9452    0.9604    0.9528      1617

all (micro avg.)     0.8846    0.9093    0.8968      5648

----------------------------------------------------------------------

** Worst ** model scores - run 4
                  precision    recall  f1-score   support

             LOC     0.8959    0.9341    0.9146      1668
            MISC     0.7732    0.7963    0.7846       702
             ORG     0.8462    0.8675    0.8567      1661
             PER     0.9421    0.9561    0.9490      1617

all (micro avg.)     0.8791    0.9037    0.8912      5648


** Best ** model scores - run 1
                  precision    recall  f1-score   support

             LOC     0.9135    0.9311    0.9222      1668
            MISC     0.8028    0.8120    0.8074       702
             ORG     0.8401    0.8856    0.8623      1661
             PER     0.9538    0.9573    0.9556      1617

all (micro avg.)     0.8890    0.9104    0.8996      5648

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9064    0.9314    0.9187      1668
            MISC     0.7907    0.7964    0.7935       702
             ORG     0.8392    0.8794    0.8588      1661
             PER     0.9484    0.9557    0.9520      1617

all (micro avg.)     0.8838    0.9063    0.8949








> python3 delft/applications/nerTagger.py train_eval --dataset-type conll2003 --architecture BERT --transformer bert-base-cased --fold-count 10

training runtime: 11087.346 seconds 

Evaluation on test set:

------------------------ fold 0 --------------------------------------
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights0.hdf5
number of alignment issues with test set: 3390
you might need to increase the maximum sequence input length of the model and retrain
    f1: 90.94
    precision: 90.22
    recall: 91.66

------------------------ fold 1 --------------------------------------
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights1.hdf5
number of alignment issues with test set: 3176
you might need to increase the maximum sequence input length of the model and retrain
    f1: 91.16
    precision: 90.29
    recall: 92.05

------------------------ fold 2 --------------------------------------
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights2.hdf5
number of alignment issues with test set: 3276
you might need to increase the maximum sequence input length of the model and retrain
    f1: 91.29
    precision: 90.49
    recall: 92.10

------------------------ fold 3 --------------------------------------
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights3.hdf5
number of alignment issues with test set: 3403
you might need to increase the maximum sequence input length of the model and retrain
    f1: 91.18
    precision: 90.35
    recall: 92.03

------------------------ fold 4 --------------------------------------
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights4.hdf5
number of alignment issues with test set: 3403
you might need to increase the maximum sequence input length of the model and retrain
    f1: 90.96
    precision: 90.14
    recall: 91.80

------------------------ fold 5 --------------------------------------
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights5.hdf5
number of alignment issues with test set: 3442
you might need to increase the maximum sequence input length of the model and retrain
    f1: 90.93
    precision: 90.15
    recall: 91.73

------------------------ fold 6 --------------------------------------
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights6.hdf5
number of alignment issues with test set: 3401
you might need to increase the maximum sequence input length of the model and retrain
    f1: 90.79
    precision: 89.88
    recall: 91.71

------------------------ fold 7 --------------------------------------
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights7.hdf5
number of alignment issues with test set: 3401
you might need to increase the maximum sequence input length of the model and retrain
    f1: 91.17
    precision: 90.39
    recall: 91.96

------------------------ fold 8 --------------------------------------
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights8.hdf5
number of alignment issues with test set: 3403
you might need to increase the maximum sequence input length of the model and retrain
    f1: 90.80
    precision: 89.83
    recall: 91.78

------------------------ fold 9 --------------------------------------
loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights9.hdf5
number of alignment issues with test set: 3415
you might need to increase the maximum sequence input length of the model and retrain
    f1: 91.07
    precision: 90.32
    recall: 91.84
----------------------------------------------------------------------

** Worst ** model scores - run 6
                  precision    recall  f1-score   support

             LOC     0.9197    0.9269    0.9233      1668
            MISC     0.7651    0.8120    0.7878       702
             ORG     0.8778    0.9085    0.8929      1661
             PER     0.9611    0.9617    0.9614      1617

all (micro avg.)     0.8988    0.9171    0.9079      5648


** Best ** model scores - run 2
                  precision    recall  f1-score   support

             LOC     0.9311    0.9317    0.9314      1668
            MISC     0.7807    0.8319    0.8055       702
             ORG     0.8863    0.9061    0.8961      1661
             PER     0.9541    0.9641    0.9591      1617

all (micro avg.)     0.9049    0.9210    0.9129      5648

loading model weights data/models/sequenceLabelling/ner-en-conll2003-BERT/model_weights2.hdf5
----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

             LOC     0.9233    0.9312    0.9272      1668
            MISC     0.7739    0.8239    0.7981       702
             ORG     0.8824    0.9042    0.8932      1661
             PER     0.9600    0.9618    0.9609      1617

all (micro avg.)     0.9021    0.9187    0.9103        











