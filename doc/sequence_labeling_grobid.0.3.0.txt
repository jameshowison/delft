citation model
==============

> python3 delft/applications/grobidTagger.py citation train_eval --architecture BidLSTM_CRF --embedding glove-840B --fold-count 10 --input data/sequenceLabelling/grobid/citation/citation-060518.train

training runtime: 40340.819 seconds 

Evaluation:

------------------------ fold 0 --------------------------------------
    f1 (micro): 94.82
                  precision    recall  f1-score   support

        <author>     0.9406    0.9421    0.9414       639
     <booktitle>     0.7500    0.7373    0.7436       118
 <collaboration>     1.0000    0.7500    0.8571        12
          <date>     0.9843    0.9843    0.9843       699
        <editor>     0.6429    0.6429    0.6429        14
   <institution>     0.7143    0.7895    0.7500        19
         <issue>     0.9275    0.9143    0.9209        70
       <journal>     0.9376    0.9516    0.9445       537
      <location>     0.8778    0.8404    0.8587        94
          <note>     0.8485    0.7179    0.7778        39
         <pages>     0.9793    0.9844    0.9818       576
     <publisher>     0.9216    0.9400    0.9307        50
        <pubnum>     0.9588    0.9118    0.9347       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.7222    0.7647    0.7429        17
         <title>     0.9606    0.9606    0.9606       457
        <volume>     0.9632    0.9850    0.9740       532
           <web>     0.9167    0.9167    0.9167        12

all (micro avg.)     0.9472    0.9491    0.9482      3989


------------------------ fold 1 --------------------------------------
    f1 (micro): 95.05
                  precision    recall  f1-score   support

        <author>     0.9498    0.9484    0.9491       639
     <booktitle>     0.7895    0.7627    0.7759       118
 <collaboration>     1.0000    0.8333    0.9091        12
          <date>     0.9900    0.9886    0.9893       699
        <editor>     0.7692    0.7143    0.7407        14
   <institution>     0.7619    0.8421    0.8000        19
         <issue>     0.9155    0.9286    0.9220        70
       <journal>     0.9353    0.9423    0.9388       537
      <location>     0.8791    0.8511    0.8649        94
          <note>     0.8182    0.6923    0.7500        39
         <pages>     0.9811    0.9896    0.9853       576
     <publisher>     0.9388    0.9200    0.9293        50
        <pubnum>     0.9485    0.9020    0.9246       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.7000    0.8235    0.7568        17
         <title>     0.9542    0.9584    0.9563       457
        <volume>     0.9631    0.9812    0.9721       532
           <web>     0.8462    0.9167    0.8800        12

all (micro avg.)     0.9499    0.9511    0.9505      3989


------------------------ fold 2 --------------------------------------
    f1 (micro): 95.42
                  precision    recall  f1-score   support

        <author>     0.9561    0.9546    0.9554       639
     <booktitle>     0.7642    0.7966    0.7801       118
 <collaboration>     0.9091    0.8333    0.8696        12
          <date>     0.9843    0.9857    0.9850       699
        <editor>     0.6923    0.6429    0.6667        14
   <institution>     0.7727    0.8947    0.8293        19
         <issue>     0.9429    0.9429    0.9429        70
       <journal>     0.9461    0.9479    0.9470       537
      <location>     0.9043    0.9043    0.9043        94
          <note>     0.7576    0.6410    0.6944        39
         <pages>     0.9793    0.9878    0.9836       576
     <publisher>     0.9592    0.9400    0.9495        50
        <pubnum>     0.9697    0.9412    0.9552       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.6667    0.7059    0.6857        17
         <title>     0.9604    0.9562    0.9583       457
        <volume>     0.9686    0.9850    0.9767       532
           <web>     1.0000    1.0000    1.0000        12

all (micro avg.)     0.9530    0.9554    0.9542      3989


------------------------ fold 3 --------------------------------------
    f1 (micro): 95.11
                  precision    recall  f1-score   support

        <author>     0.9545    0.9531    0.9538       639
     <booktitle>     0.7563    0.7627    0.7595       118
 <collaboration>     0.9091    0.8333    0.8696        12
          <date>     0.9871    0.9857    0.9864       699
        <editor>     0.6429    0.6429    0.6429        14
   <institution>     0.8000    0.8421    0.8205        19
         <issue>     0.9559    0.9286    0.9420        70
       <journal>     0.9357    0.9479    0.9417       537
      <location>     0.8804    0.8617    0.8710        94
          <note>     0.8333    0.6410    0.7246        39
         <pages>     0.9827    0.9861    0.9844       576
     <publisher>     0.9592    0.9400    0.9495        50
        <pubnum>     0.9300    0.9118    0.9208       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.7647    0.7647    0.7647        17
         <title>     0.9582    0.9540    0.9561       457
        <volume>     0.9650    0.9850    0.9749       532
           <web>     0.8333    0.8333    0.8333        12

all (micro avg.)     0.9511    0.9511    0.9511      3989


------------------------ fold 4 --------------------------------------
    f1 (micro): 95.33
                  precision    recall  f1-score   support

        <author>     0.9422    0.9437    0.9429       639
     <booktitle>     0.7750    0.7881    0.7815       118
 <collaboration>     0.9091    0.8333    0.8696        12
          <date>     0.9871    0.9871    0.9871       699
        <editor>     0.7692    0.7143    0.7407        14
   <institution>     0.7619    0.8421    0.8000        19
         <issue>     0.9412    0.9143    0.9275        70
       <journal>     0.9414    0.9572    0.9492       537
      <location>     0.9121    0.8830    0.8973        94
          <note>     0.8529    0.7436    0.7945        39
         <pages>     0.9793    0.9878    0.9836       576
     <publisher>     0.9388    0.9200    0.9293        50
        <pubnum>     0.9485    0.9020    0.9246       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.6500    0.7647    0.7027        17
         <title>     0.9647    0.9562    0.9604       457
        <volume>     0.9705    0.9887    0.9795       532
           <web>     1.0000    1.0000    1.0000        12

all (micro avg.)     0.9522    0.9544    0.9533      3989


------------------------ fold 5 --------------------------------------
    f1 (micro): 95.00
                  precision    recall  f1-score   support

        <author>     0.9437    0.9452    0.9445       639
     <booktitle>     0.7623    0.7881    0.7750       118
 <collaboration>     0.9091    0.8333    0.8696        12
          <date>     0.9843    0.9857    0.9850       699
        <editor>     0.6364    0.5000    0.5600        14
   <institution>     0.7143    0.7895    0.7500        19
         <issue>     0.9420    0.9286    0.9353        70
       <journal>     0.9458    0.9423    0.9440       537
      <location>     0.9111    0.8723    0.8913        94
          <note>     0.8065    0.6410    0.7143        39
         <pages>     0.9793    0.9844    0.9818       576
     <publisher>     0.9057    0.9600    0.9320        50
        <pubnum>     0.9691    0.9216    0.9447       102
        <series>     0.5000    0.5000    0.5000         2
          <tech>     0.6190    0.7647    0.6842        17
         <title>     0.9626    0.9562    0.9594       457
        <volume>     0.9651    0.9868    0.9758       532
           <web>     0.8333    0.8333    0.8333        12

all (micro avg.)     0.9496    0.9504    0.9500      3989


------------------------ fold 6 --------------------------------------
    f1 (micro): 95.31
                  precision    recall  f1-score   support

        <author>     0.9577    0.9577    0.9577       639
     <booktitle>     0.7731    0.7797    0.7764       118
 <collaboration>     1.0000    0.7500    0.8571        12
          <date>     0.9871    0.9814    0.9842       699
        <editor>     0.6429    0.6429    0.6429        14
   <institution>     0.8500    0.8947    0.8718        19
         <issue>     0.9412    0.9143    0.9275        70
       <journal>     0.9426    0.9479    0.9452       537
      <location>     0.8696    0.8511    0.8602        94
          <note>     0.7576    0.6410    0.6944        39
         <pages>     0.9793    0.9861    0.9827       576
     <publisher>     0.9592    0.9400    0.9495        50
        <pubnum>     0.9400    0.9216    0.9307       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.7222    0.7647    0.7429        17
         <title>     0.9669    0.9584    0.9626       457
        <volume>     0.9703    0.9831    0.9767       532
           <web>     1.0000    1.0000    1.0000        12

all (micro avg.)     0.9540    0.9521    0.9531      3989


------------------------ fold 7 --------------------------------------
    f1 (micro): 94.70
                  precision    recall  f1-score   support

        <author>     0.9467    0.9452    0.9460       639
     <booktitle>     0.7063    0.7542    0.7295       118
 <collaboration>     1.0000    0.7500    0.8571        12
          <date>     0.9843    0.9886    0.9864       699
        <editor>     0.5625    0.6429    0.6000        14
   <institution>     0.6500    0.6842    0.6667        19
         <issue>     0.9692    0.9000    0.9333        70
       <journal>     0.9442    0.9460    0.9451       537
      <location>     0.8681    0.8404    0.8541        94
          <note>     0.8387    0.6667    0.7429        39
         <pages>     0.9777    0.9878    0.9827       576
     <publisher>     0.8824    0.9000    0.8911        50
        <pubnum>     0.9495    0.9216    0.9353       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.7647    0.7647    0.7647        17
         <title>     0.9559    0.9497    0.9528       457
        <volume>     0.9668    0.9850    0.9758       532
           <web>     0.8462    0.9167    0.8800        12

all (micro avg.)     0.9462    0.9479    0.9470      3989


------------------------ fold 8 --------------------------------------
    f1 (micro): 95.12
                  precision    recall  f1-score   support

        <author>     0.9577    0.9577    0.9577       639
     <booktitle>     0.7266    0.7881    0.7561       118
 <collaboration>     1.0000    0.8333    0.9091        12
          <date>     0.9857    0.9871    0.9864       699
        <editor>     0.6923    0.6429    0.6667        14
   <institution>     0.7500    0.7895    0.7692        19
         <issue>     0.9275    0.9143    0.9209        70
       <journal>     0.9390    0.9460    0.9425       537
      <location>     0.8667    0.8298    0.8478        94
          <note>     0.7941    0.6923    0.7397        39
         <pages>     0.9776    0.9861    0.9818       576
     <publisher>     0.9423    0.9800    0.9608        50
        <pubnum>     0.9588    0.9118    0.9347       102
        <series>     1.0000    0.5000    0.6667         2
          <tech>     0.6190    0.7647    0.6842        17
         <title>     0.9621    0.9431    0.9525       457
        <volume>     0.9723    0.9887    0.9804       532
           <web>     0.9167    0.9167    0.9167        12

all (micro avg.)     0.9502    0.9521    0.9512      3989


------------------------ fold 9 --------------------------------------
    f1 (micro): 94.66
                  precision    recall  f1-score   support

        <author>     0.9544    0.9499    0.9522       639
     <booktitle>     0.7653    0.6356    0.6944       118
 <collaboration>     1.0000    0.8333    0.9091        12
          <date>     0.9801    0.9843    0.9822       699
        <editor>     0.6154    0.5714    0.5926        14
   <institution>     0.7619    0.8421    0.8000        19
         <issue>     0.9412    0.9143    0.9275        70
       <journal>     0.9375    0.9497    0.9436       537
      <location>     0.8723    0.8723    0.8723        94
          <note>     0.8710    0.6923    0.7714        39
         <pages>     0.9760    0.9896    0.9828       576
     <publisher>     0.9216    0.9400    0.9307        50
        <pubnum>     0.9583    0.9020    0.9293       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.6842    0.7647    0.7222        17
         <title>     0.9258    0.9562    0.9408       457
        <volume>     0.9668    0.9850    0.9758       532
           <web>     0.8462    0.9167    0.8800        12

all (micro avg.)     0.9453    0.9479    0.9466      3989

----------------------------------------------------------------------

** Worst ** model scores - run 9
                  precision    recall  f1-score   support

        <author>     0.9544    0.9499    0.9522       639
     <booktitle>     0.7653    0.6356    0.6944       118
 <collaboration>     1.0000    0.8333    0.9091        12
          <date>     0.9801    0.9843    0.9822       699
        <editor>     0.6154    0.5714    0.5926        14
   <institution>     0.7619    0.8421    0.8000        19
         <issue>     0.9412    0.9143    0.9275        70
       <journal>     0.9375    0.9497    0.9436       537
      <location>     0.8723    0.8723    0.8723        94
          <note>     0.8710    0.6923    0.7714        39
         <pages>     0.9760    0.9896    0.9828       576
     <publisher>     0.9216    0.9400    0.9307        50
        <pubnum>     0.9583    0.9020    0.9293       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.6842    0.7647    0.7222        17
         <title>     0.9258    0.9562    0.9408       457
        <volume>     0.9668    0.9850    0.9758       532
           <web>     0.8462    0.9167    0.8800        12

all (micro avg.)     0.9453    0.9479    0.9466      3989


** Best ** model scores - run 2
                  precision    recall  f1-score   support

        <author>     0.9561    0.9546    0.9554       639
     <booktitle>     0.7642    0.7966    0.7801       118
 <collaboration>     0.9091    0.8333    0.8696        12
          <date>     0.9843    0.9857    0.9850       699
        <editor>     0.6923    0.6429    0.6667        14
   <institution>     0.7727    0.8947    0.8293        19
         <issue>     0.9429    0.9429    0.9429        70
       <journal>     0.9461    0.9479    0.9470       537
      <location>     0.9043    0.9043    0.9043        94
          <note>     0.7576    0.6410    0.6944        39
         <pages>     0.9793    0.9878    0.9836       576
     <publisher>     0.9592    0.9400    0.9495        50
        <pubnum>     0.9697    0.9412    0.9552       102
        <series>     0.0000    0.0000    0.0000         2
          <tech>     0.6667    0.7059    0.6857        17
         <title>     0.9604    0.9562    0.9583       457
        <volume>     0.9686    0.9850    0.9767       532
           <web>     1.0000    1.0000    1.0000        12

all (micro avg.)     0.9530    0.9554    0.9542      3989

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

        <author>     0.9504    0.9498    0.9501       639
     <booktitle>     0.7569    0.7593    0.7572       118
 <collaboration>     0.9636    0.8083    0.8777        12
          <date>     0.9854    0.9858    0.9856       699
        <editor>     0.6666    0.6357    0.6496        14
   <institution>     0.7537    0.8211    0.7857        19
         <issue>     0.9404    0.9200    0.9300        70
       <journal>     0.9405    0.9479    0.9442       537
      <location>     0.8841    0.8606    0.8722        94
          <note>     0.8178    0.6769    0.7404        39
         <pages>     0.9792    0.9870    0.9831       576
     <publisher>     0.9329    0.9380    0.9352        50
        <pubnum>     0.9531    0.9147    0.9335       102
        <series>     0.1500    0.1000    0.1167         2
          <tech>     0.6913    0.7647    0.7251        17
         <title>     0.9572    0.9549    0.9560       457
        <volume>     0.9672    0.9853    0.9762       532
           <web>     0.9038    0.9250    0.9140        12

all (micro avg.)     0.9499    0.9511    0.9505 

